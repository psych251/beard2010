---
title: "WSAP Pilot Analysis: Beard & Amir (2009)"
author: "Eric Martz"
date: "`r Sys.Date()`"
output: 
  html_document:
    toc: true
    toc_float: true
    theme: cosmo
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  echo = TRUE,
  message = FALSE,
  warning = FALSE,
  fig.width = 10,
  fig.height = 6
)
```

# Study Overview

This pilot analysis replicates key findings from:

**Beard, C., & Amir, N. (2009).** Interpretation in Social Anxiety: When Meaning Precedes Ambiguity. *Cognitive Therapy and Research, 33*(4), 406-415.

The Word Sentence Association Paradigm (WSAP) assesses interpretation bias by having participants judge whether words (suggesting negative or benign interpretations) are related to ambiguous sentences.

**Note:** This is a pilot study with N = 5 participants.

---

# Setup

```{r load-packages}
library(tidyverse)
library(psych)
library(knitr)
library(kableExtra)
library(ggpubr)
library(lsr)

theme_set(theme_bw(base_size = 12))
```

## Configuration

```{r config}
PARTICIPANT_DATA_FOLDER <- "../data/" 
CODING_FILE <- "interpretation_coding_reference.csv"

# RT cleaning thresholds
RT_MIN <- 0
RT_MAX <- 10000

OUTPUT_DIR <- getwd()
```

---

# Data Loading

```{r load-data}
# Load interpretation coding
interpretation_coding <- read_csv(CODING_FILE, show_col_types = FALSE)

# Load participant data from folder
csv_files <- list.files(PARTICIPANT_DATA_FOLDER, 
                        pattern = "\\.csv$", 
                        full.names = TRUE,
                        ignore.case = TRUE)

cat("Loading", length(csv_files), "participant file(s)\n")

df_list <- lapply(csv_files, function(file) {
  temp_df <- read_csv(file, show_col_types = FALSE)
  if (!"subject" %in% names(temp_df)) {
    temp_df$subject <- tools::file_path_sans_ext(basename(file))
  }
  return(temp_df)
})

df_raw <- bind_rows(df_list)
cat("Loaded data for", n_distinct(df_raw$subject), "subjects\n")
```

---

# Data Preparation

```{r prepare-data}
# Clean and merge with interpretation coding
df <- df_raw %>%
  mutate(
    endorsed = case_when(
      response == "1" | response == 1 ~ 1,
      response == "3" | response == 3 ~ 0,
      TRUE ~ NA_real_
    ),
    rt = as.numeric(rt),
    word = str_trim(word),
    sentence = str_trim(sentence)
  ) %>%
  left_join(
    interpretation_coding %>% 
      select(word, sentence, interpretation_type, domain),
    by = c("word", "sentence")
  ) %>%
  filter(!is.na(interpretation_type), !is.na(endorsed))

# Apply RT filters
df <- df %>%
  filter(rt >= RT_MIN & rt <= RT_MAX)

cat("Total trials after cleaning:", nrow(df), "\n")
cat("Subjects:", paste(unique(df$subject), collapse = ", "), "\n")
```

---

# Calculate Subject-Level Scores

```{r subject-scores}
# Calculate endorsement rates and RT by interpretation type
subject_scores <- df %>%
  group_by(subject, interpretation_type) %>%
  summarise(
    endorsement_rate = mean(endorsed, na.rm = TRUE),
    mean_rt = mean(rt[endorsed == 1], na.rm = TRUE),
    n_trials = n(),
    .groups = "drop"
  ) %>%
  pivot_wider(
    names_from = interpretation_type,
    values_from = c(endorsement_rate, mean_rt, n_trials)
  )

# Check the actual column names and rename appropriately
# The interpretation_type values might be lowercase "negative"/"benign"
col_names <- names(subject_scores)

# Find the endorsement and RT columns
endorse_cols <- grep("endorsement_rate_", col_names, value = TRUE)
rt_cols <- grep("mean_rt_", col_names, value = TRUE)

# Rename to standard names (handling both lowercase and capitalized)
subject_scores <- subject_scores %>%
  rename_with(~"negative_endorsement", matches("endorsement_rate_(n|N)egative")) %>%
  rename_with(~"benign_endorsement", matches("endorsement_rate_(b|B)enign")) %>%
  rename_with(~"negative_rt", matches("mean_rt_(n|N)egative")) %>%
  rename_with(~"benign_rt", matches("mean_rt_(b|B)enign")) %>%
  mutate(
    # Bias scores (Negative - Benign)
    endorsement_bias = negative_endorsement - benign_endorsement,
    rt_bias = negative_rt - benign_rt
  )

# Display scores
kable(subject_scores, digits = 3, caption = "Subject-Level Scores") %>%
  kable_styling(bootstrap_options = c("striped", "hover"), full_width = FALSE)
```

---

# Group Assignment Based on SPIN Scores

```{r group-assignment}
cat("\n=== GROUP ASSIGNMENT (SPIN-Based) ===\n")

# Extract SPIN scores from participant data
spin_scores <- df_raw %>%
  filter(!is.na(spin_total)) %>%
  group_by(subject) %>%
  summarise(
    SPIN = first(spin_total),
    .groups = "drop"
  )

# Merge with subject scores
subject_scores <- subject_scores %>%
  left_join(spin_scores, by = "subject")

# Calculate 30th and 70th percentiles
percentile_30 <- quantile(subject_scores$SPIN, 0.30, na.rm = TRUE)
percentile_70 <- quantile(subject_scores$SPIN, 0.70, na.rm = TRUE)

cat("\nSPIN Percentile Cutoffs:\n")
cat("  30th percentile:", percentile_30, "\n")
cat("  70th percentile:", percentile_70, "\n\n")

# Assign groups based on percentiles
subject_scores <- subject_scores %>%
  mutate(
    group = case_when(
      SPIN <= percentile_30 ~ "LSA",
      SPIN >= percentile_70 ~ "HSA",
      TRUE ~ "Moderate"
    )
  )

cat("Group Assignment:\n")
cat("  LSA (Low Social Anxiety):  SPIN ≤", percentile_30, "\n")
cat("  HSA (High Social Anxiety): SPIN ≥", percentile_70, "\n\n")

# Show group distribution
group_table <- table(subject_scores$group)
print(group_table)

# Show individual assignments
cat("\n\nIndividual Participant Assignments:\n")
kable(subject_scores %>% 
        select(subject, SPIN, group, endorsement_bias) %>%
        arrange(SPIN),
      digits = 3,
      caption = "Participants by SPIN Score and Group") %>%
  kable_styling(bootstrap_options = c("striped", "hover"))

# Create grouped dataset (excluding Moderate)
subject_scores_grouped <- subject_scores %>%
  filter(group %in% c("HSA", "LSA"))
```

---

# Main Analysis: Interpretation Bias

## Test 1: Endorsement Rates (Negative vs Benign) - All Participants

```{r endorsement-test}
# Prepare data for paired t-test
endorsement_data <- subject_scores %>%
  select(subject, 
         negative = negative_endorsement,
         benign = benign_endorsement) %>%
  filter(!is.na(negative) & !is.na(benign))

# Paired t-test
endorsement_test <- t.test(endorsement_data$negative, 
                          endorsement_data$benign, 
                          paired = TRUE)

# Effect size
cohens_d_endorse <- cohensD(endorsement_data$negative, 
                            endorsement_data$benign, 
                            method = "paired")

# Display results
cat("\n=== ENDORSEMENT BIAS TEST (All Participants) ===\n")
cat("Negative M =", round(mean(endorsement_data$negative), 3), "\n")
cat("Benign M =", round(mean(endorsement_data$benign), 3), "\n")
cat("t(", endorsement_test$parameter, ") = ", round(endorsement_test$statistic, 3), 
    ", p = ", format.pval(endorsement_test$p.value, digits = 3), 
    ", Cohen's d = ", round(cohens_d_endorse, 3), "\n", sep = "")
```

## Test 2: Reaction Time (Negative vs Benign) - All Participants

```{r rt-test}
# Prepare RT data
rt_data <- subject_scores %>%
  select(subject,
         negative_rt, benign_rt) %>%
  filter(!is.na(negative_rt) & !is.na(benign_rt))

if (nrow(rt_data) >= 2) {
  # Paired t-test
  rt_test <- t.test(rt_data$negative_rt, 
                   rt_data$benign_rt, 
                   paired = TRUE)
  
  # Effect size
  cohens_d_rt <- cohensD(rt_data$negative_rt, 
                        rt_data$benign_rt, 
                        method = "paired")
  
  # Display results
  cat("\n=== RT BIAS TEST (All Participants) ===\n")
  cat("Negative RT M =", round(mean(rt_data$negative_rt), 2), "ms\n")
  cat("Benign RT M =", round(mean(rt_data$benign_rt), 2), "ms\n")
  cat("t(", rt_test$parameter, ") = ", round(rt_test$statistic, 3), 
      ", p = ", format.pval(rt_test$p.value, digits = 3), 
      ", Cohen's d = ", round(cohens_d_rt, 3), "\n", sep = "")
} else {
  cat("\nInsufficient data for RT analysis\n")
}
```

---

# Group Analysis: Mixed ANOVA

## Mixed ANOVA: Group × Interpretation Type

```{r mixed-anova}
if (nrow(subject_scores_grouped) >= 2) {
  
  cat("\n=== MIXED ANOVA: GROUP × INTERPRETATION TYPE ===\n")
  cat("Note: Small sample size - interpret with caution\n\n")
  
  # Prepare data in long format for ANOVA
  anova_data <- subject_scores_grouped %>%
    select(subject, group, negative_endorsement, benign_endorsement) %>%
    pivot_longer(cols = c(negative_endorsement, benign_endorsement),
                 names_to = "interpretation_type",
                 values_to = "endorsement_rate") %>%
    mutate(
      interpretation_type = factor(
        interpretation_type,
        levels = c("benign_endorsement", "negative_endorsement"),
        labels = c("Benign", "Negative")
      ),
      group = factor(group, levels = c("LSA", "HSA"))
    )
  
  # Run mixed ANOVA
  anova_result <- aov(endorsement_rate ~ group * interpretation_type + 
                      Error(subject/interpretation_type), 
                      data = anova_data)
  
  cat("ANOVA Results:\n")
  print(summary(anova_result))
  
  # Descriptive statistics by group and interpretation type
  cat("\n\nDescriptive Statistics:\n")
  desc_by_group <- anova_data %>%
    group_by(group, interpretation_type) %>%
    summarise(
      n = n(),
      mean = mean(endorsement_rate, na.rm = TRUE),
      sd = sd(endorsement_rate, na.rm = TRUE),
      se = sd / sqrt(n),
      .groups = "drop"
    )
  
  kable(desc_by_group, digits = 3,
        caption = "Mean Endorsement Rates by Group and Interpretation Type") %>%
    kable_styling(bootstrap_options = c("striped", "hover"))
  
  # POST-HOC: Within-group comparisons
  cat("\n\n=== POST-HOC: WITHIN-GROUP COMPARISONS ===\n\n")
  
  for (grp in c("HSA", "LSA")) {
    grp_data <- subject_scores_grouped %>% filter(group == grp)
    
    if (nrow(grp_data) >= 2) {
      t_result <- t.test(grp_data$negative_endorsement, 
                        grp_data$benign_endorsement, 
                        paired = TRUE)
      
      diff <- grp_data$negative_endorsement - grp_data$benign_endorsement
      d <- mean(diff) / sd(diff)
      
      cat(grp, "group (n=", nrow(grp_data), "):\n", sep = "")
      cat("  Negative: M =", round(mean(grp_data$negative_endorsement), 3), "\n")
      cat("  Benign:   M =", round(mean(grp_data$benign_endorsement), 3), "\n")
      cat("  t(", t_result$parameter, ") = ", round(t_result$statistic, 3),
          ", p = ", format.pval(t_result$p.value, digits = 3),
          ", d = ", round(d, 3), "\n\n", sep = "")
    }
  }
  
  # POST-HOC: Between-group comparisons
  cat("\n=== POST-HOC: BETWEEN-GROUP COMPARISONS ===\n\n")
  
  # Bias score comparison
  hsa_bias <- subject_scores_grouped %>% filter(group == "HSA") %>% pull(endorsement_bias)
  lsa_bias <- subject_scores_grouped %>% filter(group == "LSA") %>% pull(endorsement_bias)
  
  if (length(hsa_bias) >= 2 && length(lsa_bias) >= 2) {
    bias_test <- t.test(hsa_bias, lsa_bias)
    cat("Endorsement Bias (HSA vs LSA):\n")
    cat("  HSA: M =", round(mean(hsa_bias), 3), "\n")
    cat("  LSA: M =", round(mean(lsa_bias), 3), "\n")
    cat("  t(", round(bias_test$parameter, 1), ") = ", round(bias_test$statistic, 3),
        ", p = ", format.pval(bias_test$p.value, digits = 3), "\n", sep = "")
  }
  
} else {
  cat("\nInsufficient participants for group analysis\n")
}
```

---

# Visualizations

## Figure 1: Endorsement Rates by Interpretation Type (All Participants)

```{r fig-endorsement, fig.width=8, fig.height=6}
# Prepare data for plotting
plot_data <- subject_scores %>%
  select(subject, 
         Negative = negative_endorsement,
         Benign = benign_endorsement) %>%
  pivot_longer(cols = c(Negative, Benign),
               names_to = "Interpretation",
               values_to = "Endorsement_Rate")

# Calculate means and SEs
plot_summary <- plot_data %>%
  group_by(Interpretation) %>%
  summarise(
    mean = mean(Endorsement_Rate, na.rm = TRUE),
    se = sd(Endorsement_Rate, na.rm = TRUE) / sqrt(n()),
    .groups = "drop"
  )

# Create plot
ggplot(plot_summary, aes(x = Interpretation, y = mean, fill = Interpretation)) +
  geom_bar(stat = "identity", width = 0.6, color = "black") +
  geom_errorbar(aes(ymin = mean - se, ymax = mean + se), width = 0.2) +
  geom_jitter(data = plot_data, 
              aes(x = Interpretation, y = Endorsement_Rate, fill = Interpretation),
              width = 0.1, alpha = 0.5, size = 3, shape = 21) +
  scale_fill_manual(values = c("Negative" = "#d62728", "Benign" = "#2ca02c")) +
  labs(title = "Endorsement Rates by Interpretation Type",
       subtitle = paste0("N = ", nrow(endorsement_data), " | Error bars show ±1 SE"),
       x = "Interpretation Type",
       y = "Endorsement Rate") +
  ylim(0, 1) +
  theme(legend.position = "none",
        plot.title = element_text(face = "bold", size = 16),
        axis.title = element_text(face = "bold"))
```

## Figure 2: Individual Bias Scores

```{r fig-bias, fig.width=8, fig.height=6}
# Plot individual bias scores with group coloring
ggplot(subject_scores, aes(x = reorder(subject, SPIN), y = endorsement_bias, fill = group)) +
  geom_hline(yintercept = 0, linetype = "dashed", color = "gray40", size = 1) +
  geom_bar(stat = "identity", width = 0.6, color = "black") +
  geom_text(aes(label = sprintf("%.2f", endorsement_bias)),
            vjust = ifelse(subject_scores$endorsement_bias > 0, -0.5, 1.5),
            fontface = "bold", size = 3) +
  scale_fill_manual(values = c("HSA" = "#d62728", "LSA" = "#2ca02c", "Moderate" = "#ff7f0e"),
                   labels = c("HSA" = "High Social Anxiety", 
                             "LSA" = "Low Social Anxiety",
                             "Moderate" = "Moderate")) +
  labs(title = "Endorsement Bias Score by Subject",
       subtitle = "Bias = Negative Endorsement - Benign Endorsement",
       x = "Subject (ordered by SPIN score)",
       y = "Endorsement Bias Score",
       fill = "Group") +
  theme(legend.position = "bottom",
        plot.title = element_text(face = "bold", size = 16),
        axis.title = element_text(face = "bold"),
        axis.text.x = element_text(angle = 45, hjust = 1))
```

## Figure 3: Group × Interpretation Interaction

```{r fig-interaction, fig.width=10, fig.height=6}
if (nrow(subject_scores_grouped) >= 2) {
  
  # Calculate means and SEs for plotting
  interaction_summary <- anova_data %>%
    group_by(group, interpretation_type) %>%
    summarise(
      mean = mean(endorsement_rate, na.rm = TRUE),
      se = sd(endorsement_rate, na.rm = TRUE) / sqrt(n()),
      .groups = "drop"
    )
  
  # Line plot showing interaction
  p_interaction <- ggplot(interaction_summary, 
                         aes(x = interpretation_type, y = mean, 
                             group = group, color = group, shape = group)) +
    geom_line(size = 1.5) +
    geom_point(size = 5) +
    geom_errorbar(aes(ymin = mean - se, ymax = mean + se), width = 0.1, size = 1) +
    scale_color_manual(values = c("LSA" = "#2ca02c", "HSA" = "#d62728"),
                      labels = c("LSA" = "Low Social Anxiety", "HSA" = "High Social Anxiety")) +
    scale_shape_manual(values = c("LSA" = 16, "HSA" = 17),
                      labels = c("LSA" = "Low Social Anxiety", "HSA" = "High Social Anxiety")) +
    labs(title = "Group × Interpretation Type Interaction",
         subtitle = "Error bars show ±1 SE (Beard & Amir, 2009 key finding)",
         x = "Interpretation Type",
         y = "Endorsement Rate",
         color = "Group",
         shape = "Group") +
    ylim(0, 1) +
    theme(legend.position = "bottom",
          plot.title = element_text(face = "bold", size = 16),
          axis.title = element_text(face = "bold"))
  
  # Bar plot showing bias by group
  bias_by_group <- subject_scores_grouped %>%
    group_by(group) %>%
    summarise(
      mean_bias = mean(endorsement_bias, na.rm = TRUE),
      se_bias = sd(endorsement_bias, na.rm = TRUE) / sqrt(n()),
      .groups = "drop"
    )
  
  p_bias_group <- ggplot(bias_by_group, aes(x = group, y = mean_bias, fill = group)) +
    geom_bar(stat = "identity", width = 0.6, color = "black", alpha = 0.7) +
    geom_errorbar(aes(ymin = mean_bias - se_bias, ymax = mean_bias + se_bias), 
                  width = 0.2, size = 1) +
    geom_hline(yintercept = 0, linetype = "dashed", color = "red", size = 1) +
    geom_text(aes(label = sprintf("%.3f", mean_bias)), 
              vjust = ifelse(bias_by_group$mean_bias > 0, -1.5, 2),
              size = 5, fontface = "bold") +
    scale_fill_manual(values = c("LSA" = "#2ca02c", "HSA" = "#d62728")) +
    scale_x_discrete(labels = c("LSA" = "Low Social\nAnxiety", "HSA" = "High Social\nAnxiety")) +
    labs(title = "Endorsement Bias by Group",
         subtitle = "Negative - Benign",
         x = "Group",
         y = "Endorsement Bias Score") +
    theme(legend.position = "none",
          plot.title = element_text(face = "bold", size = 16),
          axis.title = element_text(face = "bold"))
  
  # Combine plots
  ggarrange(p_interaction, p_bias_group, ncol = 2, widths = c(1.2, 1))
}
```

---

# Summary

**Sample Size:** N = `r nrow(subject_scores)` participants  
**Groups:** HSA (n = `r sum(subject_scores$group == "HSA", na.rm=TRUE)`) | LSA (n = `r sum(subject_scores$group == "LSA", na.rm=TRUE)`)

**Key Findings:**

1. **Overall Endorsement Bias:** 
   - Mean difference = `r round(mean(subject_scores$endorsement_bias, na.rm=TRUE), 3)`
   - `r if(exists("endorsement_test")) { if(endorsement_test$p.value < 0.05) paste0("**Significant** bias detected (p = ", format.pval(endorsement_test$p.value, digits=3), ", Cohen's d = ", round(cohens_d_endorse, 2), ")") else paste0("No significant bias (p = ", format.pval(endorsement_test$p.value, digits=3), ")") } else "Test not conducted"`

2. **Response Time:** 
   - `r if(exists("rt_test")) { if(rt_test$p.value < 0.05) paste0("**Significant** RT difference (p = ", format.pval(rt_test$p.value, digits=3), ", Cohen's d = ", round(cohens_d_rt, 2), ")") else paste0("No significant RT difference (p = ", format.pval(rt_test$p.value, digits=3), ")") } else "Insufficient data for RT analysis"`

3. **Group × Interpretation Interaction:** 
   - `r if(nrow(subject_scores_grouped) >= 2) "Mixed ANOVA conducted - see results above" else "Insufficient participants for group analysis"`

**Note:** This is a pilot study with limited power. Results should be interpreted cautiously.

---

# Save Results

```{r save-results}
write_csv(subject_scores, file.path(OUTPUT_DIR, "pilot_subject_scores.csv"))
write_csv(df, file.path(OUTPUT_DIR, "pilot_cleaned_data.csv"))

cat("Results saved to:\n")
cat("  - pilot_subject_scores.csv\n")
cat("  - pilot_cleaned_data.csv\n")
```

---

# References

Beard, C., & Amir, N. (2009). Interpretation in social anxiety: When meaning precedes ambiguity. *Cognitive Therapy and Research, 33*(4), 406-415. https://doi.org/10.1007/s10608-009-9235-0